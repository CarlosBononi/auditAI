import streamlit as st
import google.generativeai as genai
from PIL import Image
from fpdf import FPDF
import io
import email
from email import policy
from datetime import datetime
import pytz

# 1. GEST√ÉO DE SESS√ÉO E AC√öMULO DE PROVAS
if "historico_pericial" not in st.session_state:
    st.session_state.historico_pericial = []
if "arquivos_acumulados" not in st.session_state:
    st.session_state.arquivos_acumulados = []
if "chat_suporte" not in st.session_state:
    st.session_state.chat_suporte = [{"role": "assistant", "content": "Ol√°! Sou o Concierge AuditIA. Conhe√ßo todos os protocolos: links, documentos, e-discovery e IA. O que vamos auditar agora?"}]

def processar_pericia():
    st.session_state.pergunta_ativa = st.session_state.campo_pergunta
    st.session_state.campo_pergunta = "" 

st.set_page_config(page_title="AuditIA - Supreme Forensic Intelligence", page_icon="üëÅÔ∏è", layout="wide")

# 2. TERM√îMETRO DE CORES BLINDADO (PONTO 1)
def aplicar_estilo_pericial(texto):
    texto_upper = texto.upper()
    if any(term in texto_upper for term in ["FRAUDE CONFIRMADA", "GOLPE", "FAKE", "SCAM"]): 
        cor, font = "#ff4b4b", "white" # RED
    elif any(term in texto_upper for term in ["ALTA ATEN√á√ÉO", "MUITA ATEN√á√ÉO", "PHISHING"]): 
        cor, font = "#ffa500", "white" # ORANGE
    elif "ATEN√á√ÉO" in texto_upper: 
        cor, font = "#f1c40f", "black" # YELLOW
    elif "SEGURO" in texto_upper or "TUDO OK" in texto_upper: 
        cor, font = "#2ecc71", "white" # GREEN
    else: 
        cor, font = "#3498db", "white" # BLUE (NEUTRAL)
    
    return f'''
    <div style="background-color: {cor}; padding: 25px; border-radius: 12px; color: {font}; 
    font-weight: bold; border: 2px solid #4a4a4a; margin-bottom: 25px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);">
        {texto}
    </div>
    '''

st.markdown("""<style>.stApp { background-color: #ffffff; color: #333333; } div.stButton > button:first-child { background-color: #4a4a4a; color: white; font-weight: bold; width: 100%; height: 4em; border-radius: 10px; }</style>""", unsafe_allow_html=True)

# 3. CONEX√ÉO RESILIENTE (FIX CAIXA ROSA)
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    model = genai.GenerativeModel('gemini-1.5-flash')
except:
    st.error("Servidor pericial em manuten√ß√£o. Aguarde 60 segundos."); st.stop()

# 4. CABE√áALHO
try:
    st.image(Image.open("Logo_AI_1.png"), width=500)
except: st.title("üëÅÔ∏è AuditIA")

st.markdown("---")

# 5. INGEST√ÉO CUMULATIVA (DRAG AND DROP)
new_files = st.file_uploader("üìÇ Arraste seus documentos, imagens ou e-mails aqui ou clique para fazer o upload:", 
                               type=["jpg", "png", "jpeg", "pdf", "eml", "pst"], accept_multiple_files=True)

if new_files:
    for f in new_files:
        if f.name not in [x['name'] for x in st.session_state.arquivos_acumulados]:
            st.session_state.arquivos_acumulados.append({'name': f.name, 'content': f.read(), 'type': f.type})

if st.session_state.arquivos_acumulados:
    st.write("üì¶ **Provas Acumuladas na Investiga√ß√£o:**")
    cols = st.columns(min(len(st.session_state.arquivos_acumulados), 6))
    for i, f in enumerate(st.session_state.arquivos_acumulados):
        with cols[i % 6]: st.caption(f"‚úÖ {f['name']}")

st.subheader("üïµÔ∏è Linha de Investiga√ß√£o")
for bloco in st.session_state.historico_pericial:
    st.markdown(aplicar_estilo_pericial(bloco), unsafe_allow_html=True)

user_query = st.text_area("üìù Pergunta ao Perito:", key="campo_pergunta", placeholder="Sua d√∫vida t√©cnica ou busca e-discovery aqui...", height=120)

# 6. MOTOR PERICIAL (CONSOLIDADO E RIGOROSO)
col_ex, col_limp = st.columns([1, 1])
with col_ex:
    if st.button("üöÄ EXECUTAR PER√çCIA", on_click=processar_pericia):
        pergunta_efetiva = st.session_state.get('pergunta_ativa', '')
        if not pergunta_efetiva and not st.session_state.arquivos_acumulados:
            st.warning("Insira material.")
        else:
            tz_br = pytz.timezone('America/Sao_Paulo'); agora = datetime.now(tz_br).strftime("%d/%m/%Y √†s %H:%M:%S")
            with st.spinner("üïµÔ∏è Realizando auditoria forense..."):
                try:
                    instrucao = f"""Aja como AuditIA, perito forense. Data: {agora}.
                    REGRAS: 
                    1. Inicie com **CLASSIFICA√á√ÉO: [TIPO]** em negrito.
                    2. Use os tipos: FRAUDE CONFIRMADA, ALTA ATEN√á√ÉO, ATEN√á√ÉO, SEGURO ou INFORMATIVO.
                    3. Analise cabe√ßalhos, metadados e anatomia de IA.
                    4. Encerre com **RESUMO DO VEREDITO:**."""
                    
                    contexto = [instrucao]
                    for h in st.session_state.historico_pericial: contexto.append(h)
                    for f in st.session_state.arquivos_acumulados:
                        if f['name'].endswith('.eml'):
                            msg = email.message_from_bytes(f['content'], policy=policy.default)
                            contexto.append(f"E-MAIL: {msg.get_body(preferencelist=('plain')).get_content()}")
                        elif f['name'].endswith('.pdf'): contexto.append({"mime_type": "application/pdf", "data": f['content']})
                        else: contexto.append(Image.open(io.BytesIO(f['content'])))
                    
                    contexto.append(pergunta_efetiva)
                    response = model.generate_content(contexto)
                    st.session_state.historico_pericial.append(response.text)
                    st.rerun()
                except: st.error("Erro na an√°lise. Verifique sua conex√£o.")

with col_limp:
    if st.button("üóëÔ∏è LIMPAR CASO"):
        st.session_state.historico_pericial = []; st.session_state.arquivos_acumulados = []; st.rerun()

# 7. CONCIERGE "SOCR√ÅTICO" (PONTO 5)
st.markdown("---")
with st.container():
    st.subheader("üí¨ Concierge AuditIA")
    for msg in st.session_state.chat_suporte:
        with st.chat_message(msg["role"]): st.write(msg["content"])
    
    if prompt_suporte := st.chat_input("D√∫vida t√©cnica?"):
        st.session_state.chat_suporte.append({"role": "user", "content": prompt_suporte})
        with st.chat_message("user"): st.write(prompt_suporte)
        with st.chat_message("assistant"):
            knowledge = """
            Voc√™ √© o Concierge AuditIA. Voc√™ sabe TUDO do sistema.
            - Audita links (phishing/dom√≠nios), documentos (metadados/selos), e-mails (.eml/.pst) e IA em fotos.
            - Limite: 5 arquivos/200MB cada.
            - REGRA: Se n√£o entender a d√∫vida, PERGUNTE para esclarecer. N√£o responda gen√©rico.
            - Responda na primeira linha. E-mail: auditaiajuda@gmail.com.
            """
            try:
                res_sup = model.generate_content(knowledge + prompt_suporte)
                st.write(res_sup.text)
                st.session_state.chat_suporte.append({"role": "assistant", "content": res_sup.text})
            except: st.write("Envie para auditaiajuda@gmail.com")
